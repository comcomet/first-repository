{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pip install pillow\n",
    "#  pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_train)\n",
    "print(raw_validation)\n",
    "print(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "for idx, (image, label) in enumerate(raw_train.take(10)):\n",
    "    plt.subplot(2, 5, idx+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'label {label}: {get_label_name(label)}')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160 # All images will be resized to 160x160\n",
    "\n",
    "def format_example(image, label):\n",
    "    image = tf.cast(image, tf.float32)  # image=float(image)같은 타입캐스팅의  텐서플로우 버전입니다.\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "for idx, (image, label) in enumerate(train.take(10)):\n",
    "    plt.subplot(2, 5, idx+1)\n",
    "    image = (image + 1) / 2\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'label {label}: {get_label_name(label)}')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=16, kernel_size=3, padding='same', activation='relu', input_shape=(160, 160, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(units=512, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image = np.array([[1, 2], [3, 4]])\n",
    "print(image.shape)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in train_batches.take(1):\n",
    "    pass\n",
    "\n",
    "image_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_steps = 20\n",
    "loss0, accuracy0 = model.evaluate(validation_batches, steps=validation_steps)\n",
    "\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in test_batches.take(1):\n",
    "    images = image_batch\n",
    "    labels = label_batch\n",
    "    predictions = model.predict(image_batch)\n",
    "    pass\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for idx, (image, label, prediction) in enumerate(zip(images, labels, predictions)):\n",
    "    plt.subplot(4, 8, idx+1)\n",
    "    image = (image + 1) / 2\n",
    "    plt.imshow(image)\n",
    "    correct = label == prediction\n",
    "    title = f'real: {label} / pred :{prediction}\\n {correct}!'\n",
    "    if not correct:\n",
    "        plt.title(title, fontdict={'color': 'red'})\n",
    "    else:\n",
    "        plt.title(title, fontdict={'color': 'blue'})\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0   # 정답을 맞춘 개수\n",
    "for image, label, prediction in zip(images, labels, predictions):\n",
    "    correct = label == prediction\n",
    "    if correct:\n",
    "        count = count + 1\n",
    "\n",
    "\n",
    "print(count / 32 * 100)    # 약 70% 내외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model VGG16\n",
    "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
    "                                         include_top=False,\n",
    "                                         weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_batch = base_model(image_batch)\n",
    "feature_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image = np.array([[1, 2],\n",
    "                  [3, 4]])\n",
    "\n",
    "flattened_image = image.flatten()\n",
    "\n",
    "print(\"Original image:\\n\", image)\n",
    "print(\"Original image shape:\", image.shape)\n",
    "print()\n",
    "print(\"Flattened image:\\n\", flattened_image)\n",
    "print(\"Flattened image shape:\", flattened_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = tf.keras.layers.Dense(512, activation='relu')\n",
    "prediction_layer = tf.keras.layers.Dense(2, activation='softmax')\n",
    "\n",
    "# feature_batch_averag가 dense_layer를 거친 결과가 다시 prediction_layer를 거치게 되면\n",
    "prediction_batch = prediction_layer(dense_layer(feature_batch_average))  \n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  dense_layer,\n",
    "  prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_steps=20\n",
    "loss0, accuracy0 = model.evaluate(validation_batches, steps = validation_steps)\n",
    "\n",
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5   # 이번에는 이전보다 훨씬 빠르게 수렴되므로 5Epoch이면 충분합니다.\n",
    "\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in test_batches.take(1):\n",
    "    images = image_batch\n",
    "    labels = label_batch\n",
    "    predictions = model.predict(image_batch)\n",
    "    pass\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for idx, (image, label, prediction) in enumerate(zip(images, labels, predictions)):\n",
    "    plt.subplot(4, 8, idx+1)\n",
    "    image = (image + 1) / 2\n",
    "    plt.imshow(image)\n",
    "    correct = label == prediction\n",
    "    title = f'real: {label} / pred :{prediction}\\n {correct}!'\n",
    "    if not correct:\n",
    "        plt.title(title, fontdict={'color': 'red'})\n",
    "    else:\n",
    "        plt.title(title, fontdict={'color': 'blue'})\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for image, label, prediction in zip(images, labels, predictions):\n",
    "    correct = label == prediction\n",
    "    if correct:\n",
    "        count = count + 1\n",
    "\n",
    "print(count / 32 * 100) # 약 95% 내외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = os.getenv(\"HOME\") + \"/aiffel/cat_vs_dog/checkpoint\"\n",
    "checkpoint_file_path = os.path.join(checkpoint_dir, 'checkpoint')\n",
    "\n",
    "if not os.path.exists('checkpoint_dir'):\n",
    "    os.mkdir('checkpoint_dir')\n",
    "    \n",
    "model.save_weights(checkpoint_file_path)     # checkpoint 파일 생성\n",
    "\n",
    "if os.path.exists(checkpoint_file_path):\n",
    "  print('checkpoint 파일 생성 OK!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir_path = os.getenv(\"HOME\") + \"/aiffel/cat_vs_dog/images\"\n",
    "os.path.exists(img_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160\n",
    "dog_image_path = os.path.join(img_dir_path, 'my_dog.jpeg')\n",
    "\n",
    "dog_image = load_img(dog_image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "dog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_image = img_to_array(dog_image).reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
    "dog_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(dog_image)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_and_predict_image(dirpath, filename, img_size=160):\n",
    "    filepath = os.path.join(dirpath, filename)\n",
    "    image = load_img(filepath, target_size=(img_size, img_size))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    image = img_to_array(image).reshape(1, img_size, img_size, 3)\n",
    "    prediction = model.predict(image)[0]\n",
    "    cat_percentage = round(prediction[0] * 100)\n",
    "    dog_percentage = round(prediction[1] * 100)\n",
    "    print(f\"This image seems {dog_percentage}% dog, and {cat_percentage}% cat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'my_dog.jpeg'\n",
    "\n",
    "show_and_predict_image(img_dir_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'my_cat.jpeg'\n",
    "\n",
    "show_and_predict_image(img_dir_path, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"cat_face.jpg\"\n",
    "show_and_predict_image(img_dir_path, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
